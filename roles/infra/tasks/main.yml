---

- name: Write backend configuration
  copy:
    content: |
      terraform {
        backend "{{ terraform_backend_type }}" { }
      }
    dest: "{{ terraform_project_path }}/backend.tf"

- name: Create Terraform plan
  community.general.terraform:
    binary_path: "{{ terraform_binary_path or omit }}"
    project_path: "{{ terraform_project_path }}"
    state: planned
    backend_config: "{{ terraform_backend_config }}"
    plan_file: terraform.plan
    force_init: yes
    init_reconfigure: yes
    variables: "{{ terraform_variables }}"
  register: _tf_plan

- name: Show Terraform plan
  debug:
    msg: "{{ _tf_plan.stdout }}"

- name: Prompt to approve Terraform plan execution
  pause:
    prompt: "Do you want to execute this plan? (Only 'yes' executes)"
  register: _tf_approve_plan
  when:
    - "'No changes. Your infrastructure matches the configuration.' not in _tf_plan.stdout"
    - 'not terraform_autoapprove | bool'

- name: End host if Terraform plan is not approved
  ansible.builtin.meta: end_host
  when: "not (( terraform_autoapprove | bool ) or ( _tf_approve_plan.user_input | bool ))"

- name: Provision infrastructure using Terraform
  community.general.terraform:
    binary_path: "{{ terraform_binary_path or omit }}"
    project_path: "{{ terraform_project_path }}"
    state: "{{ terraform_state }}"
    backend_config: "{{ terraform_backend_config }}"
    force_init: yes
    init_reconfigure: yes
    variables: "{{ terraform_variables }}"
    plan_file: terraform.plan
  register: terraform_provision

- name: Show Terraform provision output
  debug:
    msg: "{{ terraform_provision.stdout }}"
  when: "'stdout' in terraform_provision"

- name: Populate in-memory inventory
  block:
    - name: Set facts from Terraform outputs
      set_fact:
        cluster_gateway_ip: "{{ terraform_provision.outputs.cluster_gateway_ip.value }}"
        cluster_nodes: "{{ terraform_provision.outputs.cluster_nodes.value }}"

    # We allow the SSH private key file to be specified
    # If it is not, we expect a private key to be in the Terraform outputs
    - block:
        - name: Get SSH private key from Terraform output
          set_fact:
            cluster_ssh_private_key: "{{ terraform_provision.outputs.cluster_ssh_private_key.value }}"

        - name: Get tempfile for SSH private key
          tempfile:
          register: cluster_ssh_private_key_tempfile

        - name: Write cluster private key to file
          copy:
            content: "{{ cluster_ssh_private_key }}"
            dest: "{{ cluster_ssh_private_key_tempfile.path }}"
            mode: u=rw

        - name: Set fact for SSH private key file
          set_fact:
            cluster_ssh_private_key_file: "{{ cluster_ssh_private_key_tempfile.path }}"
      when: cluster_ssh_private_key_file is not defined

    - name: Set fact for SSH common args for cluster nodes
      set_fact:
        # The hosts are accessed via a bastion
        # We can't just use ProxyJump here because we need agent forwarding, which is disabled even when
        # StrictHostKeyChecking=no in the case where a host key changes and the host is still in the
        # UserKnownHostsFile
        # So we need to also make sure that the UserKnownHostsFile is empty for the proxy command
        cluster_ssh_common_args: "-o ProxyCommand='ssh -i {{ cluster_ssh_private_key_file }} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -W %h:%p {{ cluster_gateway_user }}@{{ cluster_gateway_ip }}'"

    - name: Add cluster nodes to in-memory inventory
      add_host:
        name: "{{ node.name }}"
        # Add the node to it's specified primary group and the cluster group
        groups: "{{ ['cluster'] + node.groups }}"
        ansible_host: "{{ node.ip }}"
        ansible_user: "{{ cluster_ssh_user }}"
        ansible_ssh_private_key_file: "{{ cluster_ssh_private_key_file }}"
        ansible_ssh_common_args: "{{ cluster_ssh_common_args }}"
        # Use the same inventory_dir as the host that ran Terraform
        inventory_dir: "{{ inventory_dir }}"
      loop: "{{ cluster_nodes }}"
      loop_control:
        loop_var: node
        label: "{{ node.name }}"

    - name: Set facts for nodes
      include_tasks: set_node_facts.yml
      loop: "{{ cluster_nodes }}"
      loop_control:
        loop_var: node
        label: "{{ node.name }}"

    - name: Wait for cluster nodes to become accessible
      wait_for_connection:
        # Wait for 10 mins for host to become available
        timeout: 600
      delegate_to: "{{ node.name }}"
      loop: "{{ cluster_nodes }}"
      loop_control:
        loop_var: node
        label: "{{ node.name }}"
  when: terraform_state == 'present'
